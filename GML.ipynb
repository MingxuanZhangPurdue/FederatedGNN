{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy\n",
    "import copy\n",
    "import scipy.linalg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import calculate_Atilde, cSBM\n",
    "from GFL import MLP, LR, Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node_list(csbm, A_tilde, num_train, hidden_dim, output_dim=2, n_k=40, nn_type=\"MLP\"):\n",
    "    \n",
    "    N = A_tilde.shape[0]\n",
    "    \n",
    "    input_dim= csbm.p\n",
    "    \n",
    "    node_list = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        X = []\n",
    "        \n",
    "        if (nn_type == \"MLP\"):\n",
    "            model_i = MLP(input_dim, hidden_dim, output_dim)\n",
    "            \n",
    "        elif (nn_type == \"LR\"):\n",
    "            model_i = LR(input_dim, output_dim)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Type of neural network must be either LR or MLP!\")\n",
    "            \n",
    "        \n",
    "        for j in range(n_k):\n",
    "            \n",
    "            x_j = np.sqrt(csbm.mu/N)*csbm.v[i]*csbm.u + np.random.normal(loc=0, scale=1, size=csbm.p)/np.sqrt(csbm.p)\n",
    "            \n",
    "            X.append(x_j)\n",
    "            \n",
    "        X = torch.tensor(np.array(X))\n",
    "        \n",
    "        if csbm.v[i] == -1:\n",
    "            \n",
    "            y = np.zeros(n_k)\n",
    "            \n",
    "        elif csbm.v[i] == 1:\n",
    "            \n",
    "            y = np.ones(n_k)\n",
    "\n",
    "        y = torch.tensor(y).type(torch.LongTensor)\n",
    "        \n",
    "        node_i = Node(local_model=model_i, node_idx=i, X=X, y=y)\n",
    "        \n",
    "        node_list.append(node_i)\n",
    "        \n",
    "    class1_train = np.random.choice(a=csbm.class1_ids, size=int(num_train/2), replace=False)\n",
    "    \n",
    "    class2_train = np.random.choice(a=csbm.class2_ids, size=int(num_train/2), replace=False)\n",
    "    \n",
    "    train_indices = np.concatenate((class1_train, class2_train), axis=0)\n",
    "    \n",
    "    test_indices = list(set(np.arange(N)) - set(train_indices))\n",
    "    \n",
    "    return node_list, train_indices, test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "p = 10\n",
    "d = 5\n",
    "mu = 1\n",
    "l = 2\n",
    "csbm = cSBM(N, p, d, mu, l)\n",
    "A_tilde = calculate_Atilde(csbm.A, 100, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Central_Machine():\n",
    "    \n",
    "    def __init__(self, node_list, A_tilde):\n",
    "        \n",
    "        \"\"\"\n",
    "        A_tilde: PageRank matrix\n",
    "        node_list: A list contains objects from Node class\n",
    "        \"\"\"\n",
    "        \n",
    "        self.A_tilde = A_tilde\n",
    "        self.node_list = node_list\n",
    "        self.N = len(node_list)\n",
    "        self.cmodel = None\n",
    "        \n",
    "    def init_central_parameters(self, input_dim, hidden_dim, output_dim, nn_type):\n",
    "        \n",
    "        \"\"\"\n",
    "        Initialize the central server parameter dictonary\n",
    "        \"\"\"\n",
    "        \n",
    "        if (nn_type == \"MLP\"):\n",
    "            self.cmodel = MLP(input_dim, hidden_dim, output_dim)\n",
    "            \n",
    "        elif (nn_type == \"LR\"):\n",
    "            self.cmodel = LR(input_dim, output_dim)\n",
    "        \n",
    "            \n",
    "    def collect_data(self, m):\n",
    "        \n",
    "        Xs = []\n",
    "        \n",
    "        ys = []\n",
    "        \n",
    "        for node in self.node_list:\n",
    "            \n",
    "            X, y = node.upload_data(m)\n",
    "            \n",
    "            Xs.append(X)\n",
    "            ys.append(y)\n",
    "            \n",
    "            \n",
    "        # Xs; [m, N, p]\n",
    "        # ys: [m, N] \n",
    "        Xs = torch.cat(Xs, dim=1)\n",
    "        \n",
    "        ys = torch.cat(ys, dim=1)\n",
    "        \n",
    "        return Xs, ys\n",
    "            \n",
    "            \n",
    "        \n",
    "    def train_one_epoch(self, train_indices, batch_size=10):\n",
    "        \n",
    "        # Xs: [batch_size, N, p], ys: [batch_size, N]\n",
    "        Xs, ys = self.collect_data(batch_size)\n",
    "        \n",
    "        # Hs: [batch_size, N, num_class]\n",
    "        Hs = self.cmodel(Xs)\n",
    "        \n",
    "        # Zs: [m, N, num_class], ys: [m, N]\n",
    "        Zs = torch.matmul(self.A_tilde, Hs)\n",
    "        \n",
    "        # train_Zs: [m, num_train, num_class]\n",
    "        # train_ys: [m, num_train]\n",
    "        train_Zs = Zs[:,train_indices,:]\n",
    "        train_ys = ys[:,train_indices]\n",
    "        \n",
    "\n",
    "        num_train = len(train_indices)\n",
    "\n",
    "        train_loss = F.cross_entropy(train_Zs.view(batch_size*num_train, -1), train_ys.view(batch_size*num_train))\n",
    "        \n",
    "        return train_loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GML_cSBM(node_list, train_indices, test_indices, A_tilde, input_dim, hidden_dim,\n",
    "               batch_size=20, learning_rate=0.1, opt=\"Adam\", num_epochs=10,\n",
    "               nn_type=\"MLP\", output_dim=2):\n",
    "    \n",
    "    N = A_tilde.shape[0]\n",
    "    \n",
    "    cm = Central_Machine(node_list, A_tilde)\n",
    "    \n",
    "    cm.init_central_parameters(input_dim, hidden_dim, output_dim, nn_type)\n",
    "    \n",
    "    if (opt == \"Adam\"):\n",
    "        optimizer = optim.Adam(cm.cmodel.parameters())\n",
    "            \n",
    "    else:\n",
    "        optimizer = optim.SGD(cm.cmodel.parameters(), lr=learning_rate)\n",
    "    \n",
    "    train_loss = []\n",
    "    \n",
    "    for ith in range(num_epochs):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        average_train_loss = cm.train_one_epoch(train_indices, batch_size)\n",
    "        \n",
    "        average_train_loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(average_train_loss.item())\n",
    "        \n",
    "        if (num_epochs <= 30):\n",
    "            print (\"Communication:\", ith+1, \"Average train loss:\", average_train_loss.item())\n",
    "            \n",
    "        elif (num_epochs > 30 and num_epochs <= 100):\n",
    "            if (ith % 5 == 0):\n",
    "                print (\"Communication:\", ith+1, \"Average train loss:\", average_train_loss.item())\n",
    "                \n",
    "        elif (num_epochs > 1000):\n",
    "            if (ith % 100 == 0):\n",
    "                print (\"Communication:\", ith+1, \"Average train loss:\", average_train_loss.item())\n",
    "                \n",
    "        else:\n",
    "            if (ith % 10 == 0):\n",
    "                print (\"Communication:\", ith+1, \"Average train loss:\", average_train_loss.item())\n",
    "                \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication: 1 Average train loss: 0.6858515739440918\n",
      "Communication: 101 Average train loss: 0.6733407378196716\n",
      "Communication: 201 Average train loss: 0.6616483926773071\n",
      "Communication: 301 Average train loss: 0.6474541425704956\n",
      "Communication: 401 Average train loss: 0.6341202259063721\n",
      "Communication: 501 Average train loss: 0.6303312182426453\n",
      "Communication: 601 Average train loss: 0.6141489744186401\n",
      "Communication: 701 Average train loss: 0.6116967797279358\n",
      "Communication: 801 Average train loss: 0.5889756083488464\n",
      "Communication: 901 Average train loss: 0.5748032331466675\n",
      "Communication: 1001 Average train loss: 0.567499041557312\n",
      "Communication: 1101 Average train loss: 0.5623959898948669\n",
      "Communication: 1201 Average train loss: 0.5395956635475159\n",
      "Communication: 1301 Average train loss: 0.5409956574440002\n",
      "Communication: 1401 Average train loss: 0.527929961681366\n",
      "Communication: 1501 Average train loss: 0.5320008397102356\n",
      "Communication: 1601 Average train loss: 0.5118868350982666\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-141d52ede247>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m tl = train_GML_cSBM(nl, t1, t2, A_tilde, input_dim=csbm.p, hidden_dim=200,\n\u001b[0;32m      3\u001b[0m                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                nn_type=\"LR\", output_dim=2)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-85-f0f15a387193>\u001b[0m in \u001b[0;36mtrain_GML_cSBM\u001b[1;34m(node_list, train_indices, test_indices, A_tilde, input_dim, hidden_dim, batch_size, learning_rate, opt, num_epochs, nn_type, output_dim)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0maverage_train_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0maverage_train_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-78-b19f3a4794b3>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(self, train_indices, batch_size)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;31m# Xs: [batch_size, N, p], ys: [batch_size, N]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mXs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;31m# Hs: [batch_size, N, num_class]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-78-b19f3a4794b3>\u001b[0m in \u001b[0;36mcollect_data\u001b[1;34m(self, m)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnode_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0mXs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\FederatedGNN\\GFL.py\u001b[0m in \u001b[0;36mupload_data\u001b[1;34m(self, m)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nl, t1, t2 = create_node_list(csbm, A_tilde, num_train=10, hidden_dim=100, output_dim=2, n_k=40, nn_type=\"MLP\")\n",
    "tl = train_GML_cSBM(nl, t1, t2, A_tilde, input_dim=csbm.p, hidden_dim=200,\n",
    "               batch_size=20, learning_rate=0.1, opt=\"Adam\", num_epochs=10000,\n",
    "               nn_type=\"LR\", output_dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
