{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import scipy\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, bias=False):\n",
    "        \n",
    "        super(MLP, self).__init__()\n",
    "        self.linear_1 = nn.Linear(input_dim, hidden_dim, bias=bias)\n",
    "        self.linear_2 = nn.Linear(hidden_dim, output_dim, bias=bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \"\"\"\n",
    "        x: feature vector\n",
    "        \"\"\"\n",
    "        \n",
    "        x = self.linear_1(x.type(torch.FloatTensor))\n",
    "        x = F.relu(x)\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_Atilde(A, K, alpha):\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    A: adjacent matrix, numpy array, [N, N]\n",
    "    K: number of power iterations, scalar\n",
    "    alpha: jump probability, scalar\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Number of nodes in this graph\n",
    "    N = A.shape[0]\n",
    "    \n",
    "    # Add a self loop\n",
    "    A = A + np.identity(N)\n",
    "    \n",
    "    # New degree matrix\n",
    "    D = np.diag(np.sum(A,axis=1))\n",
    "    \n",
    "    # Calculate A_hat\n",
    "    D_sqrt_inverse = scipy.linalg.inv(scipy.linalg.sqrtm(D))\n",
    "    A_hat = D_sqrt_inverse @ A @ D_sqrt_inverse\n",
    "    \n",
    "    \n",
    "    # Power iteration: A_tilde = (1-\\alpha)(\\sum_{i=0}^{K} \\alpha^{i}\\hat{A}^{i})\n",
    "    A_tilde = np.zeros((N,N))\n",
    "    A_hat_i = np.identity(N)\n",
    "    alpha_i = 1\n",
    "    for i in range(0, K+1):\n",
    "        A_tilde = A_tilde + alpha_i*A_hat_i\n",
    "        alpha_i = alpha_i*alpha\n",
    "        A_hat_i = A_hat_i @ A_hat\n",
    "    A_tilde = (1-alpha)*A_tilde\n",
    "    \n",
    "    return torch.tensor(A_tilde).type(torch.FloatTensor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cSBM:\n",
    "    \n",
    "    def __init__(self, N, p, d, mu, l):\n",
    "        \n",
    "        \"\"\"\n",
    "        N: number of nodes\n",
    "        p: feature vector dimension\n",
    "        d: average degree\n",
    "        l: lambda, hyperparameter\n",
    "        mu: mu, hyperparameter\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        # Generate class [-1, 1] for each node\n",
    "        v = np.random.choice(a = [-1, 1],\n",
    "                             size = N,\n",
    "                             replace = True,\n",
    "                             p = [0.5, 0.5])\n",
    "        \n",
    "        class1_ids = np.argwhere(v==1)\n",
    "        \n",
    "        class2_ids = np.argwhere(v==-1)\n",
    "        \n",
    "        \n",
    "        # Mask -1 to 0 and store the result in v_mask\n",
    "        v_mask = np.copy(v)\n",
    "        v_mask[v==-1] = 0\n",
    "        \n",
    "        # calculate c_in and c_out\n",
    "        c_in = d + np.sqrt(d)*l\n",
    "        c_out = d - np.sqrt(d)*l\n",
    "        \n",
    "        # Generate mu random vector with size p\n",
    "        u = np.random.normal(loc=0, scale=1/np.sqrt(p), size=p)\n",
    "        \n",
    "        # Generate adjacent matrix\n",
    "        A = np.zeros((N,N))\n",
    "        for i in range(N):\n",
    "            for j in range(i+1, N):\n",
    "                if (v[i] == v[j]):\n",
    "                    if (np.random.choice(a = [1,0],p = [c_in/N, 1-c_in/N])):\n",
    "                        A[i,j] = 1\n",
    "                    else:\n",
    "                        A[i,j] = 0\n",
    "                else:\n",
    "                    if (np.random.choice(a = [1,0],p = [c_out/N, 1-c_out/N])):\n",
    "                        A[i,j] = 1\n",
    "                    else:\n",
    "                        A[i,j] = 0\n",
    "        A = A + A.T\n",
    "        # Save all necessary parameters\n",
    "        self.v = v\n",
    "        self.v_mask = v_mask\n",
    "        self.A = A\n",
    "        self.u = u\n",
    "        self.p = p\n",
    "        self.N = N\n",
    "        self.mu = mu\n",
    "        xi = N/p\n",
    "        self.phi = np.arctan((l*np.sqrt(xi))/mu)*(2/np.pi)\n",
    "        self.class1_ids = class1_ids.reshape(-1)\n",
    "        self.class2_ids = class2_ids.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \n",
    "    \n",
    "    def __init__(self, local_model, node_idx, X, y, c):\n",
    "        \n",
    "        \"\"\"\n",
    "        local_model: neural network to learn feature representation\n",
    "        node_idx: The unique identifier for each node\n",
    "        c: The class for this node\n",
    "        data_generator: A function that can draw the desired number of features for this node\n",
    "        X: feature vectors, torch tensor\n",
    "        y: classes, torch tensor\n",
    "        \"\"\"\n",
    "        \n",
    "        self.model = local_model\n",
    "        self.idx = node_idx\n",
    "        self.c = c\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_k = X.shape[0]\n",
    "        \n",
    "        \n",
    "        \n",
    "    def upload_local_parameters(self):\n",
    "        \n",
    "        return self.model.state_dict()\n",
    "    \n",
    "    def receive_central_parameters(self, central_parameters):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for pname, param in self.model.named_parameters():\n",
    "                param.copy_(central_parameters[pname])\n",
    "                \n",
    "                \n",
    "    def upload_h(self):\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x = self.X[np.random.choice(a=self.n_k),:]\n",
    "            h = self.model(x)\n",
    "        return h\n",
    "    \n",
    "    def local_update(self, A_tilde_vv, C_v, E, batch_size, learning_rate, opt, pi):\n",
    "        \n",
    "        \"\"\"\n",
    "        E: Number of local updates\n",
    "        A_tidle_vv: The coefficient for the feature representation of node v\n",
    "        C_v: The aggregated neighborhood information for node v\n",
    "        batch_size: The number of training examples in each local training step\n",
    "        learning_rate: Learning rate for the E local updates\n",
    "        opt: The name of the optimizer we want to use for training\n",
    "        \"\"\"\n",
    "        \n",
    "        self.model.train()\n",
    "        \n",
    "        if (opt==\"Adam\"):\n",
    "            optimizer = torch.optim.Adam(self.model.parameters())\n",
    "            \n",
    "        elif (opt==\"SGD\"):\n",
    "            optimizer = torch.optim.SGD(self.model.parameters(), lr=learning_rate)\n",
    "            \n",
    "        else:\n",
    "            raise Exception(\"Please specify a correct optimizer!\")\n",
    "        \n",
    "        if (batch_size > self.n_k):\n",
    "            \n",
    "            raise Exception(\"Batch size is bigger than n_k!\")\n",
    "            \n",
    "        c, l = [], []\n",
    "            \n",
    "        for step in range(E):\n",
    "            \n",
    "            \"\"\"\n",
    "            X: 2d-tensor [batch_size, p]\n",
    "            y: 1d-tensor [batch_size,]\n",
    "            \"\"\"\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            ri = np.random.choice(a=self.n_k, replace=False, size=batch_size)\n",
    "            X, y = self.X[ri,:], self.y[ri]\n",
    "            H = self.model(X)\n",
    "            y_hat = F.log_softmax(A_tilde_vv*H + C_v, dim=1)\n",
    "            preds = torch.max(y_hat, dim=1)[1]\n",
    "            c.append((preds==y).sum())\n",
    "            loss = F.nll_loss(y_hat, y)\n",
    "            loss.backward()\n",
    "            l.append(loss.item())\n",
    "            if (self.idx == pi):\n",
    "                print (loss.item())\n",
    "            optimizer.step()\n",
    "            \n",
    "        return c, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Central_Server:\n",
    "    \n",
    "    def __init__(self, csbm, node_list, A_tilde):\n",
    "        \n",
    "        self.A_tilde = A_tilde\n",
    "        self.node_list = node_list\n",
    "        self.N = len(node_list)\n",
    "        self.central_parameters = None\n",
    "        self.cmodel = None\n",
    "        self.csbm = csbm\n",
    "        \n",
    "        \n",
    "    def init_central_parameters(self):\n",
    "        \n",
    "        self.central_parameters = copy.deepcopy(self.node_list[np.random.randint(low=0, high=self.N)].model.state_dict())\n",
    "        \n",
    "        \n",
    "    def broadcast_central_parameters(self):\n",
    "        \n",
    "        if self.central_parameters == None:\n",
    "            self.init_central_parameters()\n",
    "        \n",
    "        for node in self.node_list:\n",
    "            node.receive_central_parameters(self.central_parameters)\n",
    "        \n",
    "    def collect_hs(self):\n",
    "        \n",
    "        H = []\n",
    "        \n",
    "        for node in self.node_list:\n",
    "            h = node.upload_h()\n",
    "            H.append(h)\n",
    "    \n",
    "        return H\n",
    "    \n",
    "    def communication(self, train_indices, E, batch_size, learning_rate, aggregation, opt):\n",
    "        \n",
    "        \"\"\"\n",
    "        train_indices: A list of indices of the nodes that will be used to train\n",
    "        E: Number of local updates\n",
    "        batch_size: The numbez_u = Z_K[i,:] - H_copy[i,:]*self.A_tilde[i,i] r of training exmaples in each local update for every node\n",
    "        learning: Learning rate\n",
    "        opt: The name of the optimizer used to train.\n",
    "        aggregation: The function to aggregate the local parameters\n",
    "        \"\"\"\n",
    "        \n",
    "        self.broadcast_central_parameters()\n",
    "        \n",
    "        H = self.collect_hs()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            H_copy = torch.stack(H).clone().detach().to(device)\n",
    "            C = torch.matmul(self.A_tilde, H_copy)\n",
    "            \n",
    "        t1, t2 = False, False\n",
    "        \n",
    "        pi = train_indices[0]\n",
    "        \n",
    "        for v in train_indices:\n",
    "            \n",
    "            C_v = C[v,:] - H_copy[v,:]*self.A_tilde[v,v]\n",
    "            \n",
    "            c, l = self.node_list[v].local_update(self.A_tilde[v,v], C_v, E, batch_size, learning_rate, opt, pi)\n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "            if (self.csbm.v[v] == -1 and t1 == False):\n",
    "                \n",
    "                t1 = True\n",
    "                print (self.csbm.v[v])\n",
    "                for i in range(len(l)):\n",
    "                    print ('round: %d, %.3f' % (i,l[i]))\n",
    "                #print (self.node_list[v].model.state_dict()['linear_1.weight'])\n",
    "                \n",
    "            if (self.csbm.v[v] == 1 and t2 == False):\n",
    "                \n",
    "                t2 = True\n",
    "                \n",
    "                print (self.csbm.v[v])\n",
    "                \n",
    "                for i in range(len(l)):\n",
    "                    print ('round: %d, %.3f' % (i,l[i]))\n",
    "                #print (self.node_list[v].model.state_dict()['linear_1.weight'])\n",
    "                \n",
    "            \"\"\"\n",
    "            \n",
    "\n",
    "            \n",
    "        aggregation(self.central_parameters, self.node_list, train_indices)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def create_cmodel(self, input_dim, hidden_dim, output_dim):\n",
    "        \n",
    "        self.cmodel = MLP(input_dim, hidden_dim, output_dim).to(device)\n",
    "        \n",
    "        \n",
    "    def update_cmodel(self):\n",
    "        \n",
    "        if (self.cmodel == None):\n",
    "            self.create_cmodel()\n",
    "            \n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                for pname, param in self.cmodel.named_parameters():\n",
    "                    param.copy_(self.central_parameters[pname])\n",
    "                    \n",
    "                    \n",
    "    def test_accuracy_csbm(self, test_indices):\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        s = 0\n",
    "        \n",
    "        H = self.collect_hs()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            H_copy = torch.stack(H).clone().detach().to(device)\n",
    "            \n",
    "            C = torch.matmul(self.A_tilde, H_copy)\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "        \n",
    "            for v in test_indices:\n",
    "            \n",
    "                C_v = C[v,:] - H_copy[v,:]*self.A_tilde[v,v]\n",
    "            \n",
    "                X, y = self.node_list[v].X, self.node_list[v].y\n",
    "                \n",
    "                H = self.cmodel(X)\n",
    "                \n",
    "                y_hat = F.log_softmax(self.A_tilde[v,v]*H + C_v, dim=1)\n",
    "                \n",
    "                preds = torch.max(y_hat, dim=1)[1]\n",
    "                \n",
    "                count += (preds == y).sum().item()\n",
    "                \n",
    "                s = s + y.shape[0]\n",
    "                \n",
    "        return count/s\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CSBM(csbm, \n",
    "               A_tilde,\n",
    "               input_dim, hidden_dim, output_dim,\n",
    "               E, num_epochs, num_train, batch_size, aggregation, \n",
    "               n_k = 100, learning_rate=0.01, opt=\"Adam\"):\n",
    "    \n",
    "    N = A_tilde.shape[0]\n",
    "    \n",
    "    node_list = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        \n",
    "        X = []\n",
    "        \n",
    "        model_i = MLP(input_dim, hidden_dim, output_dim).to(device)\n",
    "        \n",
    "        for j in range(n_k):\n",
    "            \n",
    "            x_j = np.sqrt(csbm.mu/N)*csbm.v[i]*csbm.u + np.random.normal(loc=0, scale=1, size=csbm.p)/np.sqrt(csbm.p)\n",
    "            \n",
    "            X.append(x_j)\n",
    "            \n",
    "        X = torch.tensor(np.array(X)).to(device)\n",
    "        \n",
    "        if csbm.v[i] == -1:\n",
    "            \n",
    "            y = np.zeros(n_k)\n",
    "            \n",
    "        elif csbm.v[i] == 1:\n",
    "            \n",
    "            y = np.ones(n_k)\n",
    "\n",
    "        y = torch.tensor(y).type(torch.LongTensor).to(device) \n",
    "        \n",
    "        node_i = Node(local_model=model_i, node_idx=i, X=X, y=y, c=csbm.v[i])\n",
    "        \n",
    "        node_list.append(node_i)\n",
    "        \n",
    "    server = Central_Server(csbm, node_list, A_tilde)\n",
    "    \n",
    "    server.create_cmodel(input_dim, hidden_dim, output_dim)\n",
    "    \n",
    "    train_indices = np.random.choice(a=N, size=num_train, replace=False)\n",
    "    \n",
    "    print (csbm.v[train_indices].sum())\n",
    "    \n",
    "    test_indices = list(set(np.arange(N)) - set(train_indices))\n",
    "    \n",
    "    tas = []\n",
    "    \n",
    "    pre_ta = server.test_accuracy_csbm(test_indices)\n",
    "    \n",
    "    print (\"Test Accuracy before training:\", pre_ta)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        server.communication(train_indices, E, batch_size, learning_rate, aggregation, opt)\n",
    "        \n",
    "        server.update_cmodel()\n",
    "        \n",
    "        taccuracy = server.test_accuracy_csbm(test_indices)\n",
    "        tas.append(taccuracy)\n",
    "        \n",
    "        print (\"Epoch:\", epoch, \"Test accuracy:\", taccuracy)\n",
    "        \n",
    "    return tas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_agg(central_parameters, node_list, train_indices):\n",
    "    \n",
    "    num_train = len(train_indices)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for pname in central_parameters.keys():\n",
    "            \n",
    "            p = node_list[train_indices[0]].model.state_dict()[pname]\n",
    "            \n",
    "            for i in range(1, num_train):\n",
    "                \n",
    "                p = p + node_list[train_indices[i]].model.state_dict()[pname]\n",
    "            \n",
    "            p = p/num_train\n",
    "            \n",
    "            central_parameters[pname] = p            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9001680340923813"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 100\n",
    "p = 10\n",
    "d = 5\n",
    "mu = 1\n",
    "l = 2\n",
    "csbm = cSBM(N, p, d, mu, l)\n",
    "A_tilde = calculate_Atilde(csbm.A, 100, 0.95)\n",
    "csbm.phi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
